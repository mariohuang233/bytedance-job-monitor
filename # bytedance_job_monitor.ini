# bytedance_job_monitor.py

import asyncio
import hashlib
import logging
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set, Any

import openpyxl
import pandas as pd
from openpyxl.styles import PatternFill
from playwright.async_api import async_playwright, Browser

# --- 1. 配置区 ---

# 日志配置
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
)

# 文件名及路径配置
# 文件将保存在当前用户的“文稿” (Documents) 文件夹下
DOCUMENTS_PATH = Path.home() / "Documents"
OUTPUT_FILENAME = DOCUMENTS_PATH / "bytedance_jobs_tracker.xlsx"

# 任务配置
TASK_CONFIGS: List[Dict[str, Any]] = [
    {
        'id': 1,
        'name': '实习招聘',
        'sheet_name': 'intern',
        'url': "https://jobs.bytedance.com/campus/position?keywords=&category=6704215864629004552%2C6704215864591255820%2C6704216224387041544%2C6704215924712409352&location=CT_125&project=7481474995534301447%2C7468181472685164808%2C7194661644654577981%2C7194661126919358757&type=&job_hot_flag=&current=1&limit=2000&functionCategory=&tag=",
        'api_url_mark': "api/v1/search/job/posts",
        'extra_fields': []
    },
    {
        'id': 2,
        'name': '校园招聘',
        'sheet_name': 'campus',
        'url': "https://jobs.bytedance.com/campus/position?keywords=&category=6704215864629004552%2C6704215864591255820%2C6704216224387041544%2C6704215924712409352&location=CT_125&project=7525009396952582407&type=&job_hot_flag=&current=1&limit=2000&functionCategory=&tag=",
        'api_url_mark': "api/v1/search/job/posts",
        'extra_fields': ['location', 'department']
    },
    {
        'id': 3,
        'name': '社会招聘',
        'sheet_name': 'experienced',
        'url': "https://jobs.bytedance.com/experienced/position?keywords=&category=6704215864629004552%2C6704215864591255820%2C6704215924712409352%2C6704216224387041544&location=CT_125&project=&type=&job_hot_flag=&current=1&limit=600&functionCategory=&tag=",
        'api_url_mark': "api/v1/search/job/posts",
        'extra_fields': ['location', 'department']
    }
]

# --- 2. 核心逻辑区 ---

class JobMonitor:
    """字节跳动职位监控器（异步版），封装了抓取、数据处理、保存和通知的全部逻辑。"""

    def __init__(self, tasks: List[Dict[str, Any]], filename: Path, headless: bool = True):
        self.tasks = tasks
        self.filename = filename
        self.headless = headless
        self.results: List[tuple[str, str, List[Dict[str, Any]]]] = []

    @staticmethod
    def _generate_job_hash(job_data: Dict[str, Any]) -> str:
        """为职位数据生成唯一的MD5哈希值，用于识别重复职位。"""
        key_fields = ['code', 'title', 'description', 'requirement']
        hash_string = ''.join(str(job_data.get(field, '')) for field in key_fields)
        return hashlib.md5(hash_string.encode('utf-8')).hexdigest()

    def _load_existing_hashes(self) -> Dict[str, Set[str]]:
        """从现有的Excel文件中加载每个工作表的职位哈希值。"""
        existing_hashes: Dict[str, Set[str]] = {}
        if not self.filename.exists():
            logging.info(f"文件 {self.filename} 不存在，将创建新文件。")
            return existing_hashes

        try:
            with pd.ExcelFile(self.filename, engine='openpyxl') as xls:
                for sheet_name in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=sheet_name)
                    hashes = {self._generate_job_hash(row.to_dict()) for _, row in df.iterrows()}
                    existing_hashes[sheet_name] = hashes
                    logging.info(f"已从工作表 '{sheet_name}' 加载 {len(hashes)} 个职位哈希。")
        except Exception as e:
            logging.warning(f"读取现有文件 {self.filename} 出错: {e}。将作为首次运行处理。")
        return existing_hashes

    async def _run_single_task_async(self, task_config: Dict[str, Any], browser: Browser) -> None:
        """在独立的浏览器上下文中异步运行单个抓取任务。"""
        task_name = task_config['name']
        sheet_name = task_config['sheet_name']
        scraped_jobs: List[Dict[str, Any]] = []
        context = None
        
        try:
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
            )
            page = await context.new_page()
            logging.info(f"🚀 开始任务: {task_name}")

            async with page.expect_response(lambda r: task_config['api_url_mark'] in r.url, timeout=30000) as response_info:
                await page.goto(task_config['url'], wait_until="domcontentloaded")
            
            response = await response_info.value
            if response.status == 200:
                data = await response.json()
                job_list = data.get("data", {}).get("job_post_list", [])
                
                for job in job_list:
                    publish_time = datetime.fromtimestamp(job["publish_time"] / 1000)
                    job_info = {
                        "title": job.get("title"),
                        "description": job.get("description"),
                        "requirement": job.get("requirement"),
                        "publish_time": publish_time.strftime("%Y-%m-%d %H:%M:%S"),
                        "code": job.get("code"),
                    }
                    for field in task_config['extra_fields']:
                        value = job.get(field)
                        job_info[field] = value.get('name') if isinstance(value, dict) else value
                    scraped_jobs.append(job_info)
                
                logging.info(f"✅ 任务 '{task_name}' 成功获取 {len(scraped_jobs)} 个职位。")
            else:
                logging.error(f"❌ 任务 '{task_name}' API 响应状态码: {response.status}")

        except Exception as e:
            logging.error(f"❌ 任务 '{task_name}' 执行失败: {e}", exc_info=False)
        finally:
            if context:
                await context.close()
            self.results.append((sheet_name, task_name, scraped_jobs))

    def _process_results(self, existing_hashes: Dict[str, Set[str]]) -> Dict:
        """处理所有任务结果，合并数据并识别新职位。"""
        final_data_frames: Dict[str, pd.DataFrame] = {}
        summary_info: List[Dict[str, Any]] = []
        
        for sheet_name, task_name, new_jobs_data in self.results:
            if not new_jobs_data:
                summary_info.append({'task_name': task_name, 'new_count': 0, 'total_count': 0})
                continue
            
            previous_hashes = existing_hashes.get(sheet_name, set())
            
            for job in new_jobs_data:
                job_hash = self._generate_job_hash(job)
                job['is_new'] = job_hash not in previous_hashes
                
            df = pd.DataFrame(new_jobs_data)
            df = df.sort_values(by="publish_time", ascending=False)
            
            final_data_frames[sheet_name] = df
            summary_info.append({
                'task_name': task_name,
                'new_count': df['is_new'].sum(),
                'total_count': len(df)
            })
        return {"data_frames": final_data_frames, "summary": summary_info}

    def _save_and_highlight(self, data_frames: Dict[str, pd.DataFrame]) -> None:
        """将数据保存到Excel，并为新职位行应用高亮。"""
        if not data_frames:
            logging.info("没有数据需要保存。")
            return
            
        try:
            with pd.ExcelWriter(self.filename, engine='openpyxl') as writer:
                for sheet_name, df in data_frames.items():
                    display_df = df.drop(columns=['is_new'], errors='ignore')
                    display_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            workbook = openpyxl.load_workbook(self.filename)
            highlight_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
            
            for sheet_name, df in data_frames.items():
                if sheet_name in workbook.sheetnames and 'is_new' in df.columns:
                    worksheet = workbook[sheet_name]
                    for row_idx, is_new in enumerate(df['is_new'], start=2):
                        if is_new:
                            for col_idx in range(1, worksheet.max_column + 1):
                                worksheet.cell(row=row_idx, column=col_idx).fill = highlight_fill
            
            workbook.save(self.filename)
            logging.info(f"💾 数据已保存并高亮至: {self.filename}")

        except Exception as e:
            logging.error(f"⚠️ 保存或高亮Excel文件时出错: {e}")

    @staticmethod
    def _send_notification(summary: List[Dict[str, Any]]) -> None:
        """根据操作系统发送桌面通知，增强了稳定性和错误排查能力。"""
        total_new = sum(info.get('new_count', 0) for info in summary)
        total_count = sum(info.get('total_count', 0) for info in summary)
        current_time = datetime.now().strftime("%H:%M")

        if total_new > 0:
            title = "🎉 发现新职位!"
            details = "\\n".join(
                f"   • {info['task_name']}: +{info['new_count']} 个"
                for info in summary if info.get('new_count', 0) > 0
            )
            message = f"发现 {total_new} 个新丝瓜！\\n总计: {total_count} 个丝瓜\\n时间: {current_time}\\n\\n详情:\\n{details}"
            buttons = '{"稍后查看", "立即查看"}'
            default_button = '"立即查看"'
            action_script = f'do shell script "open \\"{OUTPUT_FILENAME}\\""'
        else:
            title = "✅ 监控完成"
            message = f"本次未发现新丝瓜。\\n总计: {total_count} 个丝瓜\\n时间: {current_time}"
            buttons = '{"确定"}'
            default_button = '"确定"'
            action_script = ""

        if sys.platform == "darwin":
            script = f'''
            try
                set response to display dialog "{message}" with title "{title}" buttons {buttons} default button {default_button} with icon note
                if button returned of response is "立即查看" then
                    {action_script}
                end if
            on error errMsg number errNum
                -- 此处留空，以便在用户取消或对话框自动消失时静默处理，避免Python端报错
            end try
            '''
            try:
                result = subprocess.run(
                    ['osascript', '-e', script], 
                    capture_output=True, text=True, timeout=120, check=False
                )
                if result.returncode != 0:
                    logging.error("⚠️ 发送 macOS 通知失败! AppleScript 执行出错。")
                    logging.error(f"   - 返回码: {result.returncode}")
                    logging.error(f"   - 错误输出: {result.stderr.strip()}")
                    logging.info("   - 请参考文档中的“通知问题排查指南”进行检查。")
                else:
                    logging.info("🔔 已成功触发桌面通知脚本。")
            except subprocess.TimeoutExpired:
                logging.warning("⚠️ 发送 macOS 通知超时。用户可能未在2分钟内响应对话框。")
            except Exception as e:
                logging.error(f"⚠️ 调用通知子进程时发生未知错误: {e}")
        else:
            logging.info("--- 桌面通知 (非macOS) ---")
            logging.info(f"标题: {title}")
            logging.info(message.replace("\\n", "\n"))
            logging.info("-------------------------")

    async def run_async(self, silent_mode: bool = False):
        """执行一次完整的职位监控流程（异步版）。"""
        start_time = datetime.now()
        logging.info(f"--- 开始监控 {start_time.strftime('%Y-%m-%d %H:%M:%S')} ---")
        
        # 确保输出目录存在
        DOCUMENTS_PATH.mkdir(exist_ok=True)
        
        existing_hashes = self._load_existing_hashes()
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=self.headless)
            tasks_to_run = [self._run_single_task_async(task, browser) for task in self.tasks]
            await asyncio.gather(*tasks_to_run)
            await browser.close()

        results = self._process_results(existing_hashes)
        data_frames = results["data_frames"]
        summary = results["summary"]
        
        self._save_and_highlight(data_frames)
        
        total_new = sum(info.get('new_count', 0) for info in summary)
        if not silent_mode or total_new > 0:
            logging.info("--- 监控结果 ---")
            for info in summary:
                logging.info(f"  - {info['task_name']}: 发现 {info.get('new_count', 0)} 个新丝瓜，共 {info.get('total_count', 0)} 个。")
            logging.info(f"总计新增: {total_new} 个")
        
        self._send_notification(summary)
        
        end_time = datetime.now()
        logging.info(f"--- 监控结束, 耗时: {(end_time - start_time).total_seconds():.2f} 秒 ---")

# --- 3. 主程序入口 ---
if __name__ == "__main__":
    try:
        is_silent = "--auto" in sys.argv
        monitor = JobMonitor(tasks=TASK_CONFIGS, filename=OUTPUT_FILENAME, headless=True)
        asyncio.run(monitor.run_async(silent_mode=is_silent))
        
    except KeyboardInterrupt:
        logging.info("\n⚠️ 程序被用户中断。")
        sys.exit(0)
    except Exception as e:
        if "Executable doesn't exist" in str(e):
            logging.critical("❌ Playwright 浏览器依赖未安装! 请运行 'playwright install' 命令。")
        else:
            logging.critical(f"\n❌ 程序发生严重错误: {e}", exc_info=True)
        sys.exit(1)
